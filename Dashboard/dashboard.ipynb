{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978307e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'html' from 'dash' (d:\\Study\\3. CODE\\1. Python_code_file\\Big_Data\\group_assignment\\dash.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdash\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m html, dcc, Input, Output, State, callback, dash_table\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdash_bootstrap_components\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdbc\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'html' from 'dash' (d:\\Study\\3. CODE\\1. Python_code_file\\Big_Data\\group_assignment\\dash.py)"
     ]
    }
   ],
   "source": [
    "# pip install openpyxl plotly dash dash-bootstrap-components \n",
    "\n",
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output, State, callback, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "import sys\n",
    "\n",
    "# --- Định nghĩa các hằng số cho giao diện ---\n",
    "PLOTLY_TEMPLATE = 'plotly_white'\n",
    "BLUE_COLORS_DISCRETE = px.colors.qualitative.Pastel\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "print(\"Loading data...\")\n",
    "file_path = r\"D:\\Study\\3. CODE\\1. Python_code_file\\Big_Data\\group_assignment\\Cleaned_Insurance_Claims_Data.xlsx\" # Sửa lại đường dẫn nếu cần\n",
    "try:\n",
    "    excel_file = pd.ExcelFile(file_path)\n",
    "    sheets_needed = [\"Participants\", \"Regions\", \"Claims Announcements\", \"Products\", \"Brokers\", \"Policies\"]\n",
    "    all_dfs = {}\n",
    "    for sheet in sheets_needed:\n",
    "        if sheet in excel_file.sheet_names:\n",
    "            all_dfs[sheet] = pd.read_excel(excel_file, sheet_name=sheet)\n",
    "            print(f\"Loaded sheet: {sheet}\")\n",
    "        else:\n",
    "            print(f\"Warning: Sheet '{sheet}' not found.\")\n",
    "            all_dfs[sheet] = pd.DataFrame()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {file_path}\")\n",
    "    sys.exit(f\"Exiting: Data file not found.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error loading data: {e}\")\n",
    "     sys.exit(\"Exiting due to error loading data.\")\n",
    "\n",
    "# === Customer Analysis Data Processing ===\n",
    "print(\"Processing Customer data...\")\n",
    "# ... (Giữ nguyên code xử lý Regions, merge Participants và Regions, tính Age -> tạo participants_merged_age_valid) ...\n",
    "# <<< BẮT ĐẦU CODE XỬ LÝ CUSTOMER >>>\n",
    "if 'Regions' in all_dfs and not all_dfs['Regions'].empty:\n",
    "    if 'id' in all_dfs['Regions'].columns:\n",
    "        all_dfs[\"Regions\"].drop(columns=['water_area', 'type', 'time_zone', 'name', 'county', 'area_code'], inplace=True, errors='ignore')\n",
    "        all_dfs['Regions'].rename(columns={'id': 'RegionID_Map'}, inplace=True)\n",
    "    else:\n",
    "        all_dfs['Regions']['RegionID_Map'] = None\n",
    "\n",
    "    if 'median_income' in all_dfs[\"Regions\"].columns and 'population' in all_dfs[\"Regions\"].columns and 'state' in all_dfs['Regions'].columns:\n",
    "        all_dfs[\"Regions\"]['population'] = pd.to_numeric(all_dfs[\"Regions\"]['population'], errors='coerce').fillna(0)\n",
    "        all_dfs[\"Regions\"]['median_income'] = pd.to_numeric(all_dfs[\"Regions\"]['median_income'], errors='coerce').fillna(0)\n",
    "        all_dfs[\"Regions\"][\"weighted_income\"] = all_dfs[\"Regions\"][\"median_income\"] * all_dfs[\"Regions\"][\"population\"]\n",
    "        state_weighted_data = all_dfs[\"Regions\"].groupby(\"state\").agg(\n",
    "             weighted_income_sum=(\"weighted_income\", \"sum\"), population_sum=(\"population\", \"sum\")\n",
    "        ).reset_index()\n",
    "        state_weighted_data[\"weighted_median_income\"] = state_weighted_data.apply(\n",
    "             lambda row: row[\"weighted_income_sum\"] / row[\"population_sum\"] if row[\"population_sum\"] > 0 else 0, axis=1\n",
    "        )\n",
    "        weighted_income_dict = dict(zip(state_weighted_data[\"state\"], state_weighted_data[\"weighted_median_income\"]))\n",
    "        all_dfs[\"Regions\"][\"median_income\"] = all_dfs[\"Regions\"][\"state\"].map(weighted_income_dict).fillna(0)\n",
    "        if \"weighted_income\" in all_dfs[\"Regions\"].columns:\n",
    "             all_dfs[\"Regions\"] = all_dfs[\"Regions\"].drop(columns=[\"weighted_income\"])\n",
    "\n",
    "    agg_cols = ['population', 'land_area', 'households']\n",
    "    existing_agg_cols = {col: 'sum' for col in agg_cols if col in all_dfs[\"Regions\"].columns}\n",
    "    if existing_agg_cols and 'state' in all_dfs['Regions'].columns:\n",
    "        state_totals = all_dfs[\"Regions\"].groupby(\"state\").agg(existing_agg_cols).reset_index()\n",
    "        for col in existing_agg_cols:\n",
    "            col_dict = dict(zip(state_totals[\"state\"], state_totals[col]))\n",
    "            all_dfs[\"Regions\"][col] = all_dfs[\"Regions\"][\"state\"].map(col_dict).fillna(0)\n",
    "\n",
    "if 'Participants' in all_dfs and 'Regions' in all_dfs and not all_dfs['Participants'].empty and not all_dfs['Regions'].empty :\n",
    "    if 'RegionID' in all_dfs['Participants'].columns and 'RegionID_Map' in all_dfs['Regions'].columns:\n",
    "        regions_renamed = all_dfs[\"Regions\"].add_suffix('_region')\n",
    "        participants_merged = pd.merge(\n",
    "            all_dfs[\"Participants\"], regions_renamed.rename(columns={'RegionID_Map_region': 'RegionID'}),\n",
    "            on=\"RegionID\", how=\"left\"\n",
    "        )\n",
    "        cols_from_region = [col for col in participants_merged.columns if col.endswith('_region')]\n",
    "        participants_merged['state_region'] = participants_merged['state_region'].astype(str).fillna('Unknown')\n",
    "        for col in ['median_income_region', 'population_region', 'land_area_region', 'households_region']:\n",
    "            if col in participants_merged.columns: participants_merged[col] = pd.to_numeric(participants_merged[col], errors='coerce').fillna(0)\n",
    "        for col in ['latitude_region', 'longitude_region']:\n",
    "            if col in participants_merged.columns: participants_merged[col] = pd.to_numeric(participants_merged[col], errors='coerce')\n",
    "    else:\n",
    "        participants_merged = pd.DataFrame(columns=['ParticipantID', 'Gender', 'MaritalStatus', 'BirthDate', 'RegionID', 'state_region'])\n",
    "else:\n",
    "    participants_merged = pd.DataFrame(columns=['ParticipantID', 'Gender', 'MaritalStatus', 'BirthDate', 'RegionID', 'state_region'])\n",
    "\n",
    "if 'BirthDate' in participants_merged.columns:\n",
    "    participants_merged['BirthDate'] = pd.to_datetime(participants_merged['BirthDate'], errors='coerce')\n",
    "    current_date = pd.Timestamp('2021-01-01')\n",
    "    participants_merged['Age'] = participants_merged['BirthDate'].apply(lambda x: (current_date - x).days / 365.25 if pd.notna(x) else np.nan)\n",
    "    participants_merged_age_valid = participants_merged.dropna(subset=['Age']).copy()\n",
    "    if not participants_merged_age_valid.empty:\n",
    "        participants_merged_age_valid['Age'] = participants_merged_age_valid['Age'].astype(int)\n",
    "        participants_merged_age_valid = participants_merged_age_valid[(participants_merged_age_valid['Age'] >= 0) & (participants_merged_age_valid['Age'] <= 100)]\n",
    "    else: participants_merged_age_valid = pd.DataFrame(columns=participants_merged.columns.tolist() + ['Age'])\n",
    "else:\n",
    "    participants_merged['Age'] = np.nan\n",
    "    participants_merged_age_valid = participants_merged.copy()\n",
    "\n",
    "# <<< KẾT THÚC CODE XỬ LÝ CUSTOMER >>>\n",
    "unique_states = sorted(participants_merged['state_region'].astype(str).unique()) if 'state_region' in participants_merged else []\n",
    "unique_genders = sorted(participants_merged['Gender'].astype(str).unique()) if 'Gender' in participants_merged else []\n",
    "AGE_GROUPS_DEF = [(0, 18, 'Under 18'), (18, 30, '18-30'), (30, 45, '30-45'), (45, 60, '45-60'), (60, 101, '60+')]\n",
    "print(\"Customer data processed.\")\n",
    "\n",
    "\n",
    "# === Product Analysis Data Processing ===\n",
    "print(\"Processing Product data...\")\n",
    "df_claims = all_dfs.get(\"Claims Announcements\", pd.DataFrame())\n",
    "df_products = all_dfs.get(\"Products\", pd.DataFrame())\n",
    "\n",
    "if not df_claims.empty and not df_products.empty:\n",
    "    # ... (Giữ nguyên code xử lý Product -> tạo df_prod) ...\n",
    "    df_claims['ClosingDate'] = pd.to_datetime(df_claims['ClosingDate'], errors='coerce')\n",
    "    df_claims['AnnouncementDate'] = pd.to_datetime(df_claims['AnnouncementDate'], errors='coerce')\n",
    "    df_claims['processTime'] = (df_claims['ClosingDate'] - df_claims['AnnouncementDate']).dt.days\n",
    "    df_claims = df_claims.dropna(subset=['ClosingDate', 'AnnouncementDate', 'processTime'])\n",
    "    df_claims = df_claims[df_claims[\"ClosingDate\"].dt.year < 2099]\n",
    "    df_claims = df_claims[df_claims['processTime'] >= 0]\n",
    "    required_prod_cols = ['ProductID', 'ProductSubCategory']\n",
    "    if all(col in df_products.columns for col in required_prod_cols):\n",
    "         df_products_to_merge = df_products[required_prod_cols].drop_duplicates()\n",
    "         df_prod = pd.merge(df_claims, df_products_to_merge, how='left', on=\"ProductID\")\n",
    "         df_prod['ProductSubCategory'] = df_prod['ProductSubCategory'].astype(str).fillna('Unknown')\n",
    "    else:\n",
    "         df_prod = df_claims.copy()\n",
    "         df_prod['ProductSubCategory'] = 'Unknown'\n",
    "else:\n",
    "    df_prod = pd.DataFrame(columns=['processTime', 'ProductSubCategory', 'LastForecastAmount', 'ProductID', 'ClaimID'])\n",
    "\n",
    "unique_subcategories = sorted(df_prod['ProductSubCategory'].unique()) if 'ProductSubCategory' in df_prod else []\n",
    "print(\"Product data processed.\")\n",
    "\n",
    "\n",
    "# === Broker Analysis Data Processing ===\n",
    "print(\"Processing Broker data...\")\n",
    "df_brokers = all_dfs.get(\"Brokers\", pd.DataFrame())\n",
    "df_policies = all_dfs.get(\"Policies\", pd.DataFrame())\n",
    "\n",
    "if not df_claims.empty and not df_brokers.empty:\n",
    "    # ... (Giữ nguyên code xử lý Broker -> tạo df_broker, policy_with_network) ...\n",
    "    if 'BrokerID' not in df_claims.columns or 'BrokerID' not in df_brokers.columns:\n",
    "        print(\"Warning: BrokerID missing in Claims or Brokers sheet. Broker analysis may be incomplete.\")\n",
    "        df_broker = df_claims.copy(); df_broker['DistributionNetwork'] = 'Unknown'; df_broker['DistributionChannel'] = 'Unknown'; df_broker['CommissionScheme'] = 'Unknown'; df_broker['BrokerFullName'] = 'Unknown'\n",
    "    else:\n",
    "        df_broker = pd.merge(df_claims, df_brokers, on=\"BrokerID\", how=\"left\")\n",
    "        df_broker['ClosingDate'] = pd.to_datetime(df_broker['ClosingDate'], errors='coerce')\n",
    "        df_broker['AnnouncementDate'] = pd.to_datetime(df_broker['AnnouncementDate'], errors='coerce')\n",
    "        df_broker['ClaimDuration'] = (df_broker['ClosingDate'] - df_broker['AnnouncementDate']).dt.days\n",
    "        df_broker = df_broker.dropna(subset=['ClaimDuration'])\n",
    "        df_broker = df_broker[df_broker['ClaimDuration'] >= 0]\n",
    "        for col in ['DistributionNetwork', 'DistributionChannel', 'CommissionScheme', 'BrokerFullName']:\n",
    "             if col in df_broker.columns: df_broker[col] = df_broker[col].astype(str).fillna('Unknown')\n",
    "             else: df_broker[col] = 'Unknown'\n",
    "else:\n",
    "    df_broker = pd.DataFrame(columns=['ClaimID', 'BrokerID', 'LastForecastAmount', 'ClaimDuration', 'DistributionNetwork', 'DistributionChannel', 'CommissionScheme', 'BrokerFullName'])\n",
    "\n",
    "if not df_policies.empty and not df_brokers.empty and 'BrokerID' in df_policies.columns and 'BrokerID' in df_brokers.columns:\n",
    "    policy_with_network = pd.merge(\n",
    "        df_policies, df_brokers[['BrokerID', 'DistributionNetwork', 'DistributionChannel', 'CommissionScheme']].drop_duplicates(),\n",
    "        on='BrokerID', how='left'\n",
    "    )\n",
    "    for col in ['DistributionNetwork', 'DistributionChannel', 'CommissionScheme']:\n",
    "        if col in policy_with_network.columns: policy_with_network[col] = policy_with_network[col].astype(str).fillna('Unknown')\n",
    "        else: policy_with_network[col] = 'Unknown'\n",
    "    if 'AnnualizedPolicyPremium' in policy_with_network.columns: policy_with_network['AnnualizedPolicyPremium'] = pd.to_numeric(policy_with_network['AnnualizedPolicyPremium'], errors='coerce').fillna(0)\n",
    "    else: policy_with_network['AnnualizedPolicyPremium'] = 0\n",
    "else:\n",
    "     policy_with_network = pd.DataFrame(columns=['PolicyID', 'BrokerID', 'AnnualizedPolicyPremium', 'DistributionNetwork', 'DistributionChannel', 'CommissionScheme'])\n",
    "\n",
    "unique_networks = sorted(df_broker['DistributionNetwork'].unique()) if 'DistributionNetwork' in df_broker else []\n",
    "unique_schemes = sorted(df_broker['CommissionScheme'].unique()) if 'CommissionScheme' in df_broker else []\n",
    "print(\"Broker data processed.\")\n",
    "\n",
    "\n",
    "# --- 2. Initialize Dash App ---\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
    "\n",
    "# --- 3. Define Dashboard Layout with Tabs ---\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([dbc.Col(dbc.Alert(\n",
    "                # ĐỔI TIÊU ĐỀ Ở ĐÂY\n",
    "                html.H1(\"INSURANCE CLAIMS DATA ANALYSIS\", className='text-center mb-0 fw-bold'),\n",
    "                color=\"primary\", className=\"my-4 shadow\"))\n",
    "            ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dcc.Tabs(id='main-tabs', value='tab-customer', children=[\n",
    "\n",
    "                # === Tab 1: Customer Relationship Analysis ===\n",
    "                dcc.Tab(label='Customer Relationship Analysis', value='tab-customer', children=[\n",
    "                    dbc.Container([\n",
    "                        dbc.Row([dbc.Col(dbc.Card(dbc.CardBody([dbc.Row([\n",
    "                                        dbc.Col([html.Label(\"Select Gender:\", className=\"fw-bold\"), dcc.Dropdown(id='gender-dropdown', multi=False, value='All', options=[{'label': 'All Genders', 'value': 'All'}] + [{'label': g, 'value': g} for g in unique_genders], clearable=False)], width=6),\n",
    "                                        dbc.Col([html.Label(\"Select State:\", className=\"fw-bold\"), dcc.Dropdown(id='state-dropdown', multi=False, value='All', options=[{'label': 'All States', 'value': 'All'}] + [{'label': s, 'value': s} for s in unique_states], clearable=False)], width=6),\n",
    "                                    ])]), className=\"mt-4 mb-4 shadow-sm\"))\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='age-histogram')])]), width=7, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='age-group-pie')])]), width=5, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='gender-pie')])]), width=5, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='marital-bar')])]), width=7, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                    ], fluid=True, className=\"pt-4\")\n",
    "                ]), # End Tab 1\n",
    "\n",
    "                # === Tab 2: Products Analysis ===\n",
    "                dcc.Tab(label='Products Analysis', value='tab-product', children=[\n",
    "                     dbc.Container([\n",
    "                        dbc.Row([dbc.Col(dbc.Card(dbc.CardBody([dbc.Row([\n",
    "                                        dbc.Col([html.Label(\"Select Product SubCategory:\", className=\"fw-bold\"), dcc.Dropdown(id='product-subcategory-dropdown', multi=False, value='All', options=[{'label': 'All SubCategories', 'value': 'All'}] + [{'label': sub, 'value': sub} for sub in unique_subcategories], clearable=False)], width=12),\n",
    "                                    ])]), className=\"mt-4 mb-4 shadow-sm\"))\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='prod-dist-chart')])]), width=6, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='prod-time-hist')])]), width=6, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                         dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='prod-time-cat-chart')])]), width=6, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='prod-forecast-hist')])]), width=6, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                     ], fluid=True, className=\"pt-4\")\n",
    "                ]), # End Tab 2\n",
    "\n",
    "                # === Tab 3: Broker Analysis ===\n",
    "                dcc.Tab(label='Broker Analysis', value='tab-broker', children=[\n",
    "                    dbc.Container([\n",
    "                        dbc.Row([dbc.Col(dbc.Card(dbc.CardBody([dbc.Row([\n",
    "                                        dbc.Col([html.Label(\"Select Distribution Network:\", className=\"fw-bold\"), dcc.Dropdown(id='dist-network-dropdown', multi=False, value='All', options=[{'label': 'All Networks', 'value': 'All'}] + [{'label': n, 'value': n} for n in unique_networks], clearable=False)], width=6),\n",
    "                                        dbc.Col([html.Label(\"Select Commission Scheme:\", className=\"fw-bold\"), dcc.Dropdown(id='comm-scheme-dropdown', multi=False, value='All', options=[{'label': 'All Schemes', 'value': 'All'}] + [{'label': s, 'value': s} for s in unique_schemes], clearable=False)], width=6),\n",
    "                                    ])]), className=\"mt-4 mb-4 shadow-sm\"))\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='broker-net-premium-chart')])]), width=6, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='broker-net-policy-pie')])]), width=6, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                        dbc.Row([dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='broker-channel-chart')])]), width=12, className=\"mb-4\")]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='broker-scheme-premium-claim-chart')])]), width=7, className=\"mb-4\"),\n",
    "                            dbc.Col(dbc.Card([dbc.CardBody([dcc.Graph(id='broker-scheme-duration-chart')])]), width=5, className=\"mb-4\"),\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(dbc.Card([dbc.CardHeader(\"Top 10 Brokers Analysis\"), dbc.CardBody([\n",
    "                                dbc.Row([ # Hàng 1 Top 10\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-policy-chart'), width=6),\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-claimfreq-chart'), width=6),\n",
    "                                ]),\n",
    "                                dbc.Row([ # Hàng 2 Top 10\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-claimcost-high-chart'), width=6),\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-claimcost-low-chart'), width=6),\n",
    "                                ]),\n",
    "                                dbc.Row([ # Hàng 3 Top 10\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-costpolicy-chart'), width=6),\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-lossratio-chart'), width=6),\n",
    "                                ]),\n",
    "                                dbc.Row([ # Hàng 4 Top 10 - THÊM BIỂU ĐỒ MỚI VÀO ĐÂY\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-profitratio-chart'), width=6),\n",
    "                                    dbc.Col(dcc.Graph(id='broker-top10-profitratio-low-chart'), width=6), # Biểu đồ Lowest Profit Ratio\n",
    "                                ]),\n",
    "                            ])]), width=12, className=\"mb-4\")\n",
    "                        ]),\n",
    "                    ], fluid=True, className=\"pt-4\")\n",
    "                ]), # End Tab 3\n",
    "\n",
    "            ]) # End Tabs\n",
    "        ) # End Col\n",
    "    ]) # End Row Tabs\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "\n",
    "# --- 4. Define Callbacks ---\n",
    "\n",
    "# === Callback for Customer Analysis Tab ===\n",
    "@callback(\n",
    "    Output('age-histogram', 'figure'),\n",
    "    Output('age-group-pie', 'figure'),\n",
    "    Output('gender-pie', 'figure'),\n",
    "    Output('marital-bar', 'figure'),\n",
    "    Input('gender-dropdown', 'value'),\n",
    "    Input('state-dropdown', 'value')\n",
    ")\n",
    "def update_customer_charts(selected_gender, selected_state):\n",
    "    # (Giữ nguyên logic của callback này)\n",
    "    # ...\n",
    "    filtered_df = participants_merged_age_valid.copy()\n",
    "    if selected_gender != 'All':\n",
    "        if 'Gender' in filtered_df.columns: filtered_df = filtered_df[filtered_df['Gender'] == selected_gender]\n",
    "    if selected_state != 'All':\n",
    "        if 'state_region' in filtered_df.columns: filtered_df = filtered_df[filtered_df['state_region'] == selected_state]\n",
    "\n",
    "    empty_figure = go.Figure().update_layout(template=PLOTLY_TEMPLATE, annotations=[dict(text=\"No data available for selected filters\", xref=\"paper\", yref=\"paper\", showarrow=False, font=dict(size=16))])\n",
    "    chart_title_suffix = f'({selected_gender}, {selected_state})'\n",
    "\n",
    "    # Age Histogram\n",
    "    if not filtered_df.empty and 'Age' in filtered_df.columns and not filtered_df['Age'].isnull().all():\n",
    "        mean_age_filtered = filtered_df['Age'].mean(); median_age_filtered = filtered_df['Age'].median()\n",
    "        fig_age = px.histogram(filtered_df, x='Age', nbins=20, title=f'Age Distribution {chart_title_suffix}', labels={'Age': 'Age (years)', 'count': 'Participants'}, template=PLOTLY_TEMPLATE, opacity=0.8)\n",
    "        fig_age.update_layout(title_font_size=18, bargap=0.1).update_traces(marker_color='#0d6efd')\n",
    "        if pd.notna(mean_age_filtered): fig_age.add_vline(x=mean_age_filtered, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"Mean: {mean_age_filtered:.1f}\", annotation_position=\"top left\")\n",
    "        if pd.notna(median_age_filtered): fig_age.add_vline(x=median_age_filtered, line_dash=\"dash\", line_color=\"green\", annotation_text=f\"Median: {median_age_filtered:.1f}\", annotation_position=\"bottom left\")\n",
    "    else: fig_age = go.Figure(empty_figure).update_layout(title=f'No Age Data {chart_title_suffix}')\n",
    "\n",
    "    # Age Group Pie\n",
    "    if not filtered_df.empty and 'Age' in filtered_df.columns and not filtered_df['Age'].isnull().all():\n",
    "        age_group_counts, age_group_labels = [], []\n",
    "        for min_age, max_age, label in AGE_GROUPS_DEF:\n",
    "            count = filtered_df[(filtered_df['Age'] >= min_age) & (filtered_df['Age'] < max_age)].shape[0]\n",
    "            if count > 0: age_group_counts.append(count); age_group_labels.append(label)\n",
    "        if age_group_counts:\n",
    "             fig_age_group_pie = px.pie(names=age_group_labels, values=age_group_counts, title=f'Age Group Distribution {chart_title_suffix}', hole=0.4, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE)\n",
    "             fig_age_group_pie.update_traces(textposition='outside', textinfo='percent+label').update_layout(title_font_size=18, showlegend=False)\n",
    "        else: fig_age_group_pie = go.Figure(empty_figure).update_layout(title=f'No Age Group Data {chart_title_suffix}')\n",
    "    else: fig_age_group_pie = go.Figure(empty_figure).update_layout(title=f'No Age Group Data {chart_title_suffix}')\n",
    "\n",
    "    # Gender Pie\n",
    "    if not filtered_df.empty and 'Gender' in filtered_df.columns and filtered_df['Gender'].nunique() > 0:\n",
    "        gender_counts_filtered = filtered_df['Gender'].value_counts()\n",
    "        fig_gender = px.pie(gender_counts_filtered, values=gender_counts_filtered.values, names=gender_counts_filtered.index, title=f'Gender Distribution ({selected_state})', hole=0.4, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE)\n",
    "        fig_gender.update_traces(textposition='inside', textinfo='percent+label', insidetextorientation='radial').update_layout(title_font_size=18, showlegend=True, legend_title_text='Gender')\n",
    "    else: fig_gender = go.Figure(empty_figure).update_layout(title=f'No Gender Data {chart_title_suffix}')\n",
    "\n",
    "    # Marital Status Bar\n",
    "    if not filtered_df.empty and 'MaritalStatus' in filtered_df.columns and filtered_df['MaritalStatus'].nunique() > 0:\n",
    "        marital_counts_filtered = filtered_df['MaritalStatus'].value_counts()\n",
    "        fig_marital = px.bar(marital_counts_filtered, x=marital_counts_filtered.index, y=marital_counts_filtered.values, title=f'Marital Status {chart_title_suffix}', labels={'index': 'Marital Status', 'y': 'Participants'}, text=marital_counts_filtered.values, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE)\n",
    "        fig_marital.update_traces(texttemplate='%{text:,}', textposition='outside').update_layout(title_font_size=18, xaxis_tickangle=-30)\n",
    "    else: fig_marital = go.Figure(empty_figure).update_layout(title=f'No Marital Status Data {chart_title_suffix}')\n",
    "\n",
    "    return fig_age, fig_age_group_pie, fig_gender, fig_marital\n",
    "\n",
    "# === Callback for Product Analysis Tab ===\n",
    "@callback(\n",
    "    Output('prod-dist-chart', 'figure'),\n",
    "    Output('prod-time-hist', 'figure'),\n",
    "    Output('prod-time-cat-chart', 'figure'),\n",
    "    Output('prod-forecast-hist', 'figure'),\n",
    "    Input('product-subcategory-dropdown', 'value')\n",
    ")\n",
    "def update_product_charts(selected_subcategory):\n",
    "    # (Giữ nguyên logic của callback này)\n",
    "    # ...\n",
    "    df_prod_filtered = df_prod.copy()\n",
    "    if selected_subcategory != 'All':\n",
    "        if 'ProductSubCategory' in df_prod_filtered.columns: df_prod_filtered = df_prod_filtered[df_prod_filtered['ProductSubCategory'] == selected_subcategory]\n",
    "\n",
    "    empty_figure = go.Figure().update_layout(template=PLOTLY_TEMPLATE, annotations=[dict(text=\"No data available for selected filters\", xref=\"paper\", yref=\"paper\", showarrow=False, font=dict(size=16))])\n",
    "    prod_chart_title_suffix = f'({selected_subcategory})'\n",
    "\n",
    "    # Chart 1: Claim Count by SubCategory\n",
    "    if not df_prod_filtered.empty and 'ProductSubCategory' in df_prod_filtered.columns:\n",
    "         prod_counts = df_prod_filtered['ProductSubCategory'].value_counts().reset_index(); prod_counts.columns = ['ProductSubCategory', 'claim_count']\n",
    "         prod_counts = prod_counts.sort_values('claim_count', ascending=False)\n",
    "         if not prod_counts.empty:\n",
    "              fig_prod_dist = px.bar(prod_counts, x='ProductSubCategory', y='claim_count', title=f'Claim Count by SubCategory {prod_chart_title_suffix}', labels={'ProductSubCategory': 'Sub Category', 'claim_count': 'Number of Claims'}, text='claim_count', template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE)\n",
    "              fig_prod_dist.update_traces(texttemplate='%{text:,}', textposition='outside').update_layout(title_font_size=18, xaxis_tickangle=-45)\n",
    "         else: fig_prod_dist = go.Figure(empty_figure).update_layout(title=f'No Claim Count Data {prod_chart_title_suffix}')\n",
    "    else: fig_prod_dist = go.Figure(empty_figure).update_layout(title=f'No Claim Count Data {prod_chart_title_suffix}')\n",
    "\n",
    "    # Chart 2: Process time histogram\n",
    "    if not df_prod_filtered.empty and 'processTime' in df_prod_filtered.columns and not df_prod_filtered['processTime'].isnull().all():\n",
    "        fig_prod_time_hist = px.histogram(df_prod_filtered, x='processTime', nbins=30, title=f'Process Time Distribution {prod_chart_title_suffix}', labels={'processTime': 'Days', 'count': 'Number of Claims'}, template=PLOTLY_TEMPLATE)\n",
    "        fig_prod_time_hist.update_layout(title_font_size=18, bargap=0.1).update_traces(marker_color='#5bc0de')\n",
    "    else: fig_prod_time_hist = go.Figure(empty_figure).update_layout(title=f'No Process Time Data {prod_chart_title_suffix}')\n",
    "\n",
    "    # Chart 3: Average Process time by category (Bar Chart)\n",
    "    if not df_prod_filtered.empty and 'processTime' in df_prod_filtered.columns and 'ProductSubCategory' in df_prod_filtered.columns and not df_prod_filtered['processTime'].isnull().all():\n",
    "        if selected_subcategory == 'All' or df_prod_filtered['ProductSubCategory'].nunique() > 1 : avg_process_time = df_prod_filtered.groupby('ProductSubCategory')['processTime'].mean().reset_index()\n",
    "        else: avg_process_time = df_prod_filtered[['ProductSubCategory', 'processTime']].drop_duplicates(); avg_process_time['processTime'] = avg_process_time['processTime'].mean()\n",
    "        avg_process_time = avg_process_time.sort_values('processTime', ascending=False)\n",
    "        if not avg_process_time.empty:\n",
    "            fig_prod_time_cat = px.bar(avg_process_time, y='ProductSubCategory', x='processTime', orientation='h', title=f'Average Process Time by SubCategory {prod_chart_title_suffix}', labels={'processTime': 'Average Days', 'ProductSubCategory': 'Sub Category'}, text='processTime', template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE)\n",
    "            fig_prod_time_cat.update_traces(texttemplate='%{text:.0f} days', textposition='outside').update_layout(title_font_size=18, yaxis={'categoryorder':'total ascending'})\n",
    "        else: fig_prod_time_cat = go.Figure(empty_figure).update_layout(title=f'No Avg Process Time Data {prod_chart_title_suffix}')\n",
    "    else: fig_prod_time_cat = go.Figure(empty_figure).update_layout(title=f'No Avg Process Time Data {prod_chart_title_suffix}')\n",
    "\n",
    "    # Chart 4: Frequency distribution of last forecast amount\n",
    "    if not df_prod_filtered.empty and 'LastForecastAmount' in df_prod_filtered.columns and not df_prod_filtered['LastForecastAmount'].isnull().all():\n",
    "         df_forecast_valid = df_prod_filtered[df_prod_filtered['LastForecastAmount'] >= 0]\n",
    "         if not df_forecast_valid.empty:\n",
    "             fig_prod_forecast_hist = px.histogram(df_forecast_valid, x='LastForecastAmount', nbins=30, title=f'Last Forecast Amount Distribution {prod_chart_title_suffix}', labels={'LastForecastAmount': 'Amount ($)', 'count': 'Frequency'}, template=PLOTLY_TEMPLATE)\n",
    "             fig_prod_forecast_hist.update_layout(title_font_size=18, bargap=0.1).update_traces(marker_color='#337ab7')\n",
    "         else: fig_prod_forecast_hist = go.Figure(empty_figure).update_layout(title=f'No Valid Forecast Data {prod_chart_title_suffix}')\n",
    "    else: fig_prod_forecast_hist = go.Figure(empty_figure).update_layout(title=f'No Forecast Data {prod_chart_title_suffix}')\n",
    "\n",
    "    return fig_prod_dist, fig_prod_time_hist, fig_prod_time_cat, fig_prod_forecast_hist\n",
    "\n",
    "# === Callback for Broker Analysis Tab ===\n",
    "@callback(\n",
    "    Output('broker-net-premium-chart', 'figure'),\n",
    "    Output('broker-net-policy-pie', 'figure'),\n",
    "    Output('broker-channel-chart', 'figure'),\n",
    "    Output('broker-scheme-premium-claim-chart', 'figure'),\n",
    "    Output('broker-scheme-duration-chart', 'figure'),\n",
    "    Output('broker-top10-policy-chart', 'figure'),\n",
    "    Output('broker-top10-claimcost-high-chart', 'figure'),\n",
    "    Output('broker-top10-claimcost-low-chart', 'figure'),\n",
    "    Output('broker-top10-claimfreq-chart', 'figure'),\n",
    "    Output('broker-top10-costpolicy-chart', 'figure'),\n",
    "    Output('broker-top10-lossratio-chart', 'figure'),\n",
    "    Output('broker-top10-profitratio-chart', 'figure'),\n",
    "    # THÊM OUTPUT MỚI\n",
    "    Output('broker-top10-profitratio-low-chart', 'figure'),\n",
    "    Input('dist-network-dropdown', 'value'),\n",
    "    Input('comm-scheme-dropdown', 'value')\n",
    ")\n",
    "def update_broker_charts(selected_network, selected_scheme):\n",
    "    # (Giữ nguyên phần lọc dữ liệu từ code trước)\n",
    "    df_broker_filtered = df_broker.copy()\n",
    "    policy_with_network_filtered = policy_with_network.copy()\n",
    "    if selected_network != 'All':\n",
    "        if 'DistributionNetwork' in df_broker_filtered.columns: df_broker_filtered = df_broker_filtered[df_broker_filtered['DistributionNetwork'] == selected_network]\n",
    "        if 'DistributionNetwork' in policy_with_network_filtered.columns: policy_with_network_filtered = policy_with_network_filtered[policy_with_network_filtered['DistributionNetwork'] == selected_network]\n",
    "    if selected_scheme != 'All':\n",
    "        if 'CommissionScheme' in df_broker_filtered.columns: df_broker_filtered = df_broker_filtered[df_broker_filtered['CommissionScheme'] == selected_scheme]\n",
    "        if 'CommissionScheme' in policy_with_network_filtered.columns: policy_with_network_filtered = policy_with_network_filtered[policy_with_network_filtered['CommissionScheme'] == selected_scheme]\n",
    "\n",
    "    # Figure trống\n",
    "    empty_figure = go.Figure().update_layout(template=PLOTLY_TEMPLATE, annotations=[dict(text=\"No data for filter\", xref=\"paper\", yref=\"paper\", showarrow=False, font=dict(size=16))])\n",
    "    broker_chart_title_suffix = f'({selected_network}, {selected_scheme})'\n",
    "    title_size = 16\n",
    "\n",
    "    # --- Tính toán lại các bảng summary ---\n",
    "    # Network Summary\n",
    "    network_summary_filtered = policy_with_network_filtered.groupby('DistributionNetwork').agg(PolicyCount=('PolicyID', 'count'),TotalPolicyPremium=('AnnualizedPolicyPremium', 'sum')).reset_index()\n",
    "    if not network_summary_filtered.empty and 'PolicyCount' in network_summary_filtered.columns and network_summary_filtered['PolicyCount'].sum() > 0 : network_summary_filtered['AvgPremium'] = network_summary_filtered['TotalPolicyPremium'] / network_summary_filtered['PolicyCount']\n",
    "    else: network_summary_filtered['AvgPremium'] = 0\n",
    "\n",
    "    # Channel Summary\n",
    "    policy_channel_summary = policy_with_network_filtered.groupby('DistributionChannel').agg(PolicyCount=('PolicyID', 'count'), TotalPolicyPremium=('AnnualizedPolicyPremium', 'sum')).reset_index()\n",
    "    claims_channel_summary = df_broker_filtered.groupby('DistributionChannel').agg(ClaimCount=('ClaimID', 'count'), TotalForecastAmount=('LastForecastAmount', 'sum')).reset_index()\n",
    "    channel_summary_filtered = pd.merge(policy_channel_summary, claims_channel_summary, on='DistributionChannel', how='outer').fillna(0)\n",
    "    if not channel_summary_filtered.empty and 'PolicyCount' in channel_summary_filtered.columns and channel_summary_filtered['PolicyCount'].sum() > 0 :\n",
    "        channel_summary_filtered['ClaimPerPolicy'] = channel_summary_filtered['ClaimCount'] / channel_summary_filtered['PolicyCount']\n",
    "        channel_summary_filtered['PremiumPerPolicy'] = channel_summary_filtered['TotalPolicyPremium'] / channel_summary_filtered['PolicyCount']\n",
    "        channel_summary_filtered['ForecastPerPolicy'] = channel_summary_filtered['TotalForecastAmount'] / channel_summary_filtered['PolicyCount']\n",
    "    else:\n",
    "        channel_summary_filtered['ClaimPerPolicy'] = 0; channel_summary_filtered['PremiumPerPolicy'] = 0; channel_summary_filtered['ForecastPerPolicy'] = 0\n",
    "    channel_long_filtered = channel_summary_filtered.melt(id_vars='DistributionChannel', value_vars=['PremiumPerPolicy', 'ClaimPerPolicy', 'ForecastPerPolicy'], var_name='Metric', value_name='Value')\n",
    "\n",
    "    # Commission Scheme Summary\n",
    "    policy_cs_summary = policy_with_network_filtered.groupby('CommissionScheme').agg(PolicyCount=('PolicyID', 'count'), TotalPolicyPremium=('AnnualizedPolicyPremium', 'sum')).reset_index()\n",
    "    claims_cs_summary = df_broker_filtered.groupby('CommissionScheme').agg(ClaimCount=('ClaimID', 'count'), TotalForecastAmount=('LastForecastAmount', 'sum')).reset_index()\n",
    "    cs_forecast_filtered = pd.merge(policy_cs_summary, claims_cs_summary, on='CommissionScheme', how='outer').fillna(0)\n",
    "    if not cs_forecast_filtered.empty and 'PolicyCount' in cs_forecast_filtered.columns and cs_forecast_filtered['PolicyCount'].sum() > 0:\n",
    "        cs_forecast_filtered['AvgTotalPremiumPerPolicy'] = cs_forecast_filtered['TotalPolicyPremium'] / cs_forecast_filtered['PolicyCount']\n",
    "        cs_forecast_filtered['AvgForecastClaimPerPolicy'] = cs_forecast_filtered['TotalForecastAmount'] / cs_forecast_filtered['PolicyCount']\n",
    "    else: cs_forecast_filtered['AvgTotalPremiumPerPolicy'] = 0; cs_forecast_filtered['AvgForecastClaimPerPolicy'] = 0\n",
    "    cs_long_filtered = cs_forecast_filtered.melt(id_vars='CommissionScheme', value_vars=['AvgTotalPremiumPerPolicy', 'AvgForecastClaimPerPolicy'], var_name='Metric', value_name='Value')\n",
    "\n",
    "    # Top 10 Broker Calculations\n",
    "    policy_counts_broker = policy_with_network_filtered.groupby('BrokerID').size().reset_index(name='PolicyCount')\n",
    "    policy_counts_broker = pd.merge(policy_counts_broker, df_brokers[['BrokerID','BrokerFullName']], on='BrokerID', how='left')\n",
    "    top10_policies_filt = policy_counts_broker.sort_values(\"PolicyCount\", ascending=False).head(10)\n",
    "\n",
    "    avg_claim_cost_broker = df_broker_filtered.groupby('BrokerID')['LastForecastAmount'].mean().reset_index(name='AvgClaimCost')\n",
    "    avg_claim_cost_broker = pd.merge(avg_claim_cost_broker, df_brokers[['BrokerID','BrokerFullName']], on='BrokerID', how='left')\n",
    "    top10_high_cost_filt = avg_claim_cost_broker.sort_values(\"AvgClaimCost\", ascending=False).head(10)\n",
    "    top10_low_cost_filt = avg_claim_cost_broker.sort_values(\"AvgClaimCost\", ascending=True).head(10)\n",
    "\n",
    "    claims_per_broker_filt = df_broker_filtered.groupby('BrokerID').size().reset_index(name='ClaimCount')\n",
    "    policy_counts_filt = policy_with_network_filtered.groupby('BrokerID').size().reset_index(name='PolicyCount')\n",
    "    freq_df_filt = pd.merge(claims_per_broker_filt, policy_counts_filt, on='BrokerID', how='inner')\n",
    "    if not freq_df_filt.empty and freq_df_filt['PolicyCount'].sum() > 0: freq_df_filt['ClaimFrequency'] = freq_df_filt['ClaimCount'] / freq_df_filt['PolicyCount']\n",
    "    else: freq_df_filt['ClaimFrequency'] = 0\n",
    "    freq_df_filt = pd.merge(freq_df_filt, df_brokers[['BrokerID','BrokerFullName']], on='BrokerID', how='left')\n",
    "    top10_freq_filt = freq_df_filt.sort_values(\"ClaimFrequency\", ascending=False).head(10)\n",
    "\n",
    "    total_cost_by_broker_filt = df_broker_filtered.groupby('BrokerID')['LastForecastAmount'].sum().reset_index(name='TotalClaimCost')\n",
    "    cost_policy_df_filt = pd.merge(total_cost_by_broker_filt, policy_counts_filt, on='BrokerID', how='inner')\n",
    "    if not cost_policy_df_filt.empty and cost_policy_df_filt['PolicyCount'].sum() > 0: cost_policy_df_filt['CostPerPolicy'] = cost_policy_df_filt['TotalClaimCost'] / cost_policy_df_filt['PolicyCount']\n",
    "    else: cost_policy_df_filt['CostPerPolicy'] = 0\n",
    "    cost_policy_df_filt = pd.merge(cost_policy_df_filt, df_brokers[['BrokerID','BrokerFullName']], on='BrokerID', how='left')\n",
    "    top10_cost_policy_filt = cost_policy_df_filt.sort_values(\"CostPerPolicy\", ascending=False).head(10)\n",
    "\n",
    "    claims_cost_filt = df_broker_filtered.groupby('BrokerID')['LastForecastAmount'].sum().reset_index(name='TotalClaimCost')\n",
    "    premiums_filt = policy_with_network_filtered.groupby('BrokerID')['AnnualizedPolicyPremium'].sum().reset_index(name='TotalPremium')\n",
    "    loss_df_filt = pd.merge(claims_cost_filt, premiums_filt, on='BrokerID', how='inner')\n",
    "    if not loss_df_filt.empty:\n",
    "        loss_df_filt['LossRatio'] = loss_df_filt.apply(lambda row: row['TotalClaimCost'] / row['TotalPremium'] if row['TotalPremium'] > 0 else 0, axis=1)\n",
    "        loss_df_filt['ProfitRatio'] = loss_df_filt.apply(lambda row: row['TotalPremium'] / row['TotalClaimCost'] if row['TotalClaimCost'] > 0 else np.inf, axis=1)\n",
    "    else: loss_df_filt['LossRatio'] = 0; loss_df_filt['ProfitRatio'] = 0\n",
    "    loss_df_filt = pd.merge(loss_df_filt, df_brokers[['BrokerID','BrokerFullName']], on='BrokerID', how='left')\n",
    "    top10_loss_filt = loss_df_filt.sort_values(\"LossRatio\", ascending=False).head(10)\n",
    "    # Lấy top 10 Profit cao nhất (bỏ inf)\n",
    "    top10_profit_filt = loss_df_filt.replace([np.inf, -np.inf], np.nan).dropna(subset=['ProfitRatio']).sort_values(\"ProfitRatio\", ascending=False).head(10)\n",
    "    # Lấy top 10 Profit thấp nhất (bỏ inf, sắp xếp tăng dần)\n",
    "    top10_profit_low_filt = loss_df_filt.replace([np.inf, -np.inf], np.nan).dropna(subset=['ProfitRatio']).sort_values(\"ProfitRatio\", ascending=True).head(10)\n",
    "\n",
    "    # --- Tạo Figures ---\n",
    "    # (Giữ nguyên code tạo các figure khác từ code trước)\n",
    "    # ... fig_net_premium, fig_net_policy_pie, fig_channel, fig_scheme_prem_claim, fig_scheme_duration ...\n",
    "    # Network Premium Bar\n",
    "    if not network_summary_filtered.empty: fig_net_premium = px.bar(network_summary_filtered, x='DistributionNetwork', y='AvgPremium', title=f'Avg Premium by Network {broker_chart_title_suffix}', labels={'AvgPremium': 'Avg Annualized Premium'}, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_layout(title_font_size=title_size, xaxis_tickangle=-30)\n",
    "    else: fig_net_premium = go.Figure(empty_figure).update_layout(title='No Network Premium Data')\n",
    "    # Network Policy Pie\n",
    "    if not network_summary_filtered.empty and network_summary_filtered['PolicyCount'].sum() > 0: fig_net_policy_pie = px.pie(network_summary_filtered, names='DistributionNetwork', values='PolicyCount', title=f'Policy Distribution by Network {broker_chart_title_suffix}', hole=0.4, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_traces(textposition='inside', textinfo='percent+label').update_layout(title_font_size=title_size, showlegend=False)\n",
    "    else: fig_net_policy_pie = go.Figure(empty_figure).update_layout(title='No Network Policy Data')\n",
    "    # Channel Grouped Bar\n",
    "    if not channel_long_filtered.empty: fig_channel = px.bar(channel_long_filtered, x='DistributionChannel', y='Value', color='Metric', barmode='group', title=f'Channel Metrics {broker_chart_title_suffix}', labels={'Value': 'Average Value per Policy'}, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_layout(title_font_size=title_size, xaxis_tickangle=-45)\n",
    "    else: fig_channel = go.Figure(empty_figure).update_layout(title='No Channel Data')\n",
    "    # Scheme Grouped Bar (Premium vs Claim)\n",
    "    if not cs_long_filtered.empty: fig_scheme_prem_claim = px.bar(cs_long_filtered, x='CommissionScheme', y='Value', color='Metric', barmode='group', title=f'Avg Premium vs Forecast Claim by Scheme {broker_chart_title_suffix}', labels={'Value': 'Average Value per Policy'}, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_layout(title_font_size=title_size, xaxis_tickangle=-45)\n",
    "    else: fig_scheme_prem_claim = go.Figure(empty_figure).update_layout(title='No Scheme Premium/Claim Data')\n",
    "    # Scheme Duration Violin\n",
    "    if not df_broker_filtered.empty and 'ClaimDuration' in df_broker_filtered.columns and not df_broker_filtered['ClaimDuration'].isnull().all():\n",
    "         lower_bound_v = df_broker_filtered['ClaimDuration'].quantile(0.02); upper_bound_v = df_broker_filtered['ClaimDuration'].quantile(0.98)\n",
    "         df_broker_violin = df_broker_filtered[(df_broker_filtered['ClaimDuration'] >= lower_bound_v) & (df_broker_filtered['ClaimDuration'] <= upper_bound_v)]\n",
    "         if not df_broker_violin.empty:\n",
    "              fig_scheme_duration = px.violin(df_broker_violin, x='CommissionScheme', y='ClaimDuration', title=f'Claim Duration Distribution by Scheme {broker_chart_title_suffix}', labels={'ClaimDuration': 'Claim Duration (days)'}, template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_layout(title_font_size=title_size, xaxis_tickangle=-45)\n",
    "         else: fig_scheme_duration = go.Figure(empty_figure).update_layout(title=f'No Scheme Duration Data (after trim)')\n",
    "    else: fig_scheme_duration = go.Figure(empty_figure).update_layout(title=f'No Scheme Duration Data')\n",
    "\n",
    "    # Top 10 Charts\n",
    "    fig_top10_policy = px.bar(top10_policies_filt, y='BrokerFullName', x='PolicyCount', orientation='h', title=f'Top 10 Policy Count {broker_chart_title_suffix}', labels={'PolicyCount': 'Policy Count'}, text='PolicyCount', template=PLOTLY_TEMPLATE, color_discrete_sequence=BLUE_COLORS_DISCRETE).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_policies_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Policy Data')\n",
    "    fig_top10_cost_h = px.bar(top10_high_cost_filt, y='BrokerFullName', x='AvgClaimCost', orientation='h', title=f'Top 10 Highest Avg Claim Cost {broker_chart_title_suffix}', labels={'AvgClaimCost': 'Avg Claim Cost ($)'}, text='AvgClaimCost', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Pastel1).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_high_cost_filt.empty else go.Figure(empty_figure).update_layout(title='No Top High Cost Data')\n",
    "    fig_top10_cost_l = px.bar(top10_low_cost_filt, y='BrokerFullName', x='AvgClaimCost', orientation='h', title=f'Top 10 Lowest Avg Claim Cost {broker_chart_title_suffix}', labels={'AvgClaimCost': 'Avg Claim Cost ($)'}, text='AvgClaimCost', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Pastel2).update_layout(yaxis={'categoryorder':'total descending'}, title_font_size=title_size) if not top10_low_cost_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Low Cost Data')\n",
    "    fig_top10_freq = px.bar(top10_freq_filt, y='BrokerFullName', x='ClaimFrequency', orientation='h', title=f'Top 10 Highest Claim Freq {broker_chart_title_suffix}', labels={'ClaimFrequency': 'Avg Claims per Policy'}, text='ClaimFrequency', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Set1).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_freq_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Freq Data')\n",
    "    fig_top10_costpol = px.bar(top10_cost_policy_filt, y='BrokerFullName', x='CostPerPolicy', orientation='h', title=f'Top 10 Highest Claim Cost/Policy {broker_chart_title_suffix}', labels={'CostPerPolicy': 'Cost per Policy ($)'}, text='CostPerPolicy', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Set2).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_cost_policy_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Cost/Policy Data')\n",
    "    fig_top10_loss = px.bar(top10_loss_filt, y='BrokerFullName', x='LossRatio', orientation='h', title=f'Top 10 Highest Loss Ratio {broker_chart_title_suffix}', labels={'LossRatio': 'Loss Ratio'}, text='LossRatio', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Set3).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_loss_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Loss Ratio Data')\n",
    "    fig_top10_profit = px.bar(top10_profit_filt, y='BrokerFullName', x='ProfitRatio', orientation='h', title=f'Top 10 Highest Profit Ratio {broker_chart_title_suffix}', labels={'ProfitRatio': 'Profit Ratio'}, text='ProfitRatio', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Safe).update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=title_size) if not top10_profit_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Profit Ratio Data')\n",
    "\n",
    "    # TẠO FIGURE MỚI CHO LOWEST PROFIT RATIO\n",
    "    fig_top10_profit_low = px.bar(top10_profit_low_filt, y='BrokerFullName', x='ProfitRatio', orientation='h', title=f'Top 10 Lowest Profit Ratio {broker_chart_title_suffix}', labels={'ProfitRatio': 'Profit Ratio'}, text='ProfitRatio', template=PLOTLY_TEMPLATE, color_discrete_sequence=px.colors.qualitative.Pastel1).update_layout(yaxis={'categoryorder':'total descending'}, title_font_size=title_size) if not top10_profit_low_filt.empty else go.Figure(empty_figure).update_layout(title='No Top Low Profit Ratio Data')\n",
    "\n",
    "\n",
    "    # Cập nhật định dạng text cho các bar chart top 10\n",
    "    for fig in [fig_top10_policy, fig_top10_cost_h, fig_top10_cost_l, fig_top10_costpol, fig_top10_loss, fig_top10_profit, fig_top10_profit_low]: # Thêm fig mới\n",
    "        if fig.data: fig.update_traces(texttemplate='%{text:,.2f}', textposition='outside')\n",
    "    if fig_top10_freq.data: fig_top10_freq.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "\n",
    "\n",
    "    # TRẢ VỀ FIGURE MỚI Ở CUỐI\n",
    "    return (fig_net_premium, fig_net_policy_pie, fig_channel, fig_scheme_prem_claim,\n",
    "            fig_scheme_duration, fig_top10_policy, fig_top10_cost_h, fig_top10_cost_l,\n",
    "            fig_top10_freq, fig_top10_costpol, fig_top10_loss, fig_top10_profit, fig_top10_profit_low)\n",
    "\n",
    "\n",
    "# --- 5. Run the App ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting Dash server...\")\n",
    "    app.run(debug=True, port=8051)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
